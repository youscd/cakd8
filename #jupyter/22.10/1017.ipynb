{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62459a07-6f66-42a0-b5ee-9f4e65733983",
   "metadata": {},
   "source": [
    "### 1014"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c054c741-1c2c-47ce-bc25-ab8b8eeb4885",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 1 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ccf809-6401-4340-8503-b84986c709e0",
   "metadata": {},
   "source": [
    "loss = error = 오차<br>\n",
    "\n",
    "loss function 손실함수<br>\n",
    "= cost function 비용함수<br>\n",
    "= objective function 목적함수<br>\n",
    "\n",
    "learning_rate(eta) 학습률 (오차 수정률)<br>\n",
    "n_estimators weak leaner 의 개수 (몇 개의 나무를 심을 것인지, 분류기를 몇 개 사용할 것인지)<br>\n",
    "subsample weak leaner가 학습에 사용하는 데이터의 샘플링 비율, overfitting 을 방지하기 위해 1보다 작은 값으로 설정 가능, 기본값은 1 (전체 데이터 사용)<br>\n",
    "early_stopping_rounds 조기 중단, 최소 오차 지점에서 몇 번 더 검사를 할 것인가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d1949b-56b1-459c-9cb0-12a4371db160",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f337927f-766e-4365-b8af-af73c7197b4b",
   "metadata": {},
   "source": [
    "voting 방식 : 모든 데이터에 대하여 서로 다른 알고리즘을 가진 분류기를 결합한 것<br>\n",
    "bagging 방식 : 1개의 알고리즘과 여러개의 데이터 샘플을 나누어 가진다<br>\n",
    "\n",
    "* 앙상블 기법의 조건<br>\n",
    "각각의 분류기는 상호 독립적 이어야 한다<br>\n",
    "각 분류기의 오분류울은 적어도 50% 보다는 낮아야 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4ef7ed-921a-45e9-9386-1c1f57b886f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 3 틀린 것을 고르세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78069f6d-84a4-4627-9e52-4a997e35d859",
   "metadata": {},
   "source": [
    "틀린 것을 고르세요.  (답 4)\n",
    "1. 앙상블 학습의 목표는 다양한 의견을 수렴하여 신뢰성 높은 예측값을 얻는 것이다.\n",
    "2. 보팅은 서로 다른 알고리즘을 갖는 것이다.\n",
    "3. 배깅은 데이터 샘플링을 서로 다르게 하지만 같은 알고리즘을 갖는다.\n",
    "4. 보팅 방식의 대표는 랜덤 포레스트이다. \n",
    "5. 배깅 방식은 중첩을 허용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107e47f6-9259-4a6f-aa66-c827eff79ecd",
   "metadata": {},
   "source": [
    "틀린 것을 고르세요.  (답 2, 5)\n",
    "1. 하드 보팅은 다수결의 원칙과 비슷하고, 소프트 보팅은 각 확률의 평균하여 예측 결정한다.\n",
    "2. 보팅 방식은 여러개의 분류기를 결합한다고 해서 예측 성능이 좋아지지 않는다.\n",
    "3. 랜덤 포레스트는 각자의 데이터 샘플링을 하고 최종적으로 소프트 보팅으로 예측 결정한다. \n",
    "4. 부트스트래핑이란 데이터를 중첩되게 샘플링하는 것이다. \n",
    "5. 랜덤 포레스트의 트리를 분할하는 피처를 참조 시 sqrt(전체)가 아닌 전체이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1032442-7b68-48fc-b990-5fbff6ff273b",
   "metadata": {},
   "source": [
    "틀린 것을 고르세요.  (답 5)\n",
    "1. 부스팅 방식은 잘못 예측한 데이터에 가중치를 부여해서 오류를 개선해가는 학습 방식이다.\n",
    "2. GBM은 경사하강법을 사용한다. \n",
    "3. GBM은 랜덤포레스트 보다 예측성능이 뛰어나지만 시간이 오래 걸린다는 단점이 있다. \n",
    "4. XGBoost는 랜덤포레스트보다는 속도가 느리지만 GBM에 비해 학습 속도가 빠르다. \n",
    "5. 파이썬 XGBoost와 사이킷런 XGBoost는 early_stopping_rounds를 제공하지 않는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8dbbd6-f2aa-473a-ac04-66c849ab69b9",
   "metadata": {},
   "source": [
    "XGBoost 에서 과적합 문제를 해결하기 위해 고려해야 할 사항이 아닌 것은?  (답 b, d)<br>\n",
    "a. max_depth 값을 낮춘다.<br>\n",
    "b. min_child_weight 값을 낮춘다.<br>\n",
    "c. gamma 값을 높인다.<br>\n",
    "d. eta 값을 낮춘다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618d0073-1e2d-4ff5-a3f3-014d0f6563fb",
   "metadata": {},
   "source": [
    "#### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dfa4015-08c1-415a-9246-735f6ee3d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09db58ae-1411-4c01-a56c-3dc3870cd0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db8d7669-8a73-4756-af2e-a5e6b700c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris() \n",
    "\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "gnb_clf = GaussianNB()\n",
    "vo_clf = VotingClassifier(estimators = [('LR', lr_clf), ('KNN', knn_clf), ('GNB', gnb_clf)],\n",
    "                          voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "836d359b-d9a9-4a21-bdff-841aca44093b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=.2)\n",
    "\n",
    "vo_clf.fit(X_train,y_train) \n",
    "pred = vo_clf.predict(X_test) \n",
    "\n",
    "accuracy_score(y_test, pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb3dddf-a46b-420c-b6e0-e5eab21f7db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7fd3fb2-3fdb-4da5-aa3a-d2a76523e14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  0,  0],\n",
       "       [ 0, 11,  2],\n",
       "       [ 0,  0,  8]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b678c389-1f16-41a9-94b5-daa67a3e809f",
   "metadata": {},
   "source": [
    "### 1017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bda462-a49e-4525-8401-e2e6f865ca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피쳐중요도 시각화\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "# 사이킷런 래퍼 클래스를 입력해도 무방. \n",
    "plot_importance(xgb_wrapper, ax=ax) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebc71dd-4fc9-43f6-85a0-5a01b84c67e8",
   "metadata": {},
   "source": [
    "#### (6) LightGBM\n",
    "설치 방법<br>\n",
    "아나콘다 프롬프트 실행\n",
    "conda install -c conda-forge lightgbm 입력<br>\n",
    "Proceed ([y]/n)? y 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "466de2b0-012a-4caf-a4e9-3ed06e406a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67fbf5d-88c2-4520-9e90-27541f8c699e",
   "metadata": {},
   "source": [
    "#### * LightGBM 적용 - 위스콘신 유방암 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5192686c-e0e0-407e-8a21-94aa875ca8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LightGBM의 파이썬 패키지인 lightgbm에서 LGBMClassifier 임포트\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d7f0de7-f877-4dbb-9818-5463498d5c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "cancer_df = pd.DataFrame(data = cancer.data, columns = cancer.feature_names)\n",
    "cancer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9dc5abf-3ff5-47ec-9759-0ac2e1049e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df['target'] = cancer.target\n",
    "cancer_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30cfab99-b5ff-425f-8cea-0773f819776a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.625671\tvalid_1's binary_logloss: 0.628248\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\ttraining's binary_logloss: 0.588173\tvalid_1's binary_logloss: 0.601106\n",
      "[3]\ttraining's binary_logloss: 0.554518\tvalid_1's binary_logloss: 0.577587\n",
      "[4]\ttraining's binary_logloss: 0.523972\tvalid_1's binary_logloss: 0.556324\n",
      "[5]\ttraining's binary_logloss: 0.49615\tvalid_1's binary_logloss: 0.537407\n",
      "[6]\ttraining's binary_logloss: 0.470108\tvalid_1's binary_logloss: 0.519401\n",
      "[7]\ttraining's binary_logloss: 0.446647\tvalid_1's binary_logloss: 0.502637\n",
      "[8]\ttraining's binary_logloss: 0.425055\tvalid_1's binary_logloss: 0.488311\n",
      "[9]\ttraining's binary_logloss: 0.405125\tvalid_1's binary_logloss: 0.474664\n",
      "[10]\ttraining's binary_logloss: 0.386526\tvalid_1's binary_logloss: 0.461267\n",
      "[11]\ttraining's binary_logloss: 0.367027\tvalid_1's binary_logloss: 0.444274\n",
      "[12]\ttraining's binary_logloss: 0.350713\tvalid_1's binary_logloss: 0.432755\n",
      "[13]\ttraining's binary_logloss: 0.334601\tvalid_1's binary_logloss: 0.421371\n",
      "[14]\ttraining's binary_logloss: 0.319854\tvalid_1's binary_logloss: 0.411418\n",
      "[15]\ttraining's binary_logloss: 0.306374\tvalid_1's binary_logloss: 0.402989\n",
      "[16]\ttraining's binary_logloss: 0.293116\tvalid_1's binary_logloss: 0.393973\n",
      "[17]\ttraining's binary_logloss: 0.280812\tvalid_1's binary_logloss: 0.384801\n",
      "[18]\ttraining's binary_logloss: 0.268352\tvalid_1's binary_logloss: 0.376191\n",
      "[19]\ttraining's binary_logloss: 0.256942\tvalid_1's binary_logloss: 0.368378\n",
      "[20]\ttraining's binary_logloss: 0.246443\tvalid_1's binary_logloss: 0.362062\n",
      "[21]\ttraining's binary_logloss: 0.236874\tvalid_1's binary_logloss: 0.355162\n",
      "[22]\ttraining's binary_logloss: 0.227501\tvalid_1's binary_logloss: 0.348933\n",
      "[23]\ttraining's binary_logloss: 0.218988\tvalid_1's binary_logloss: 0.342819\n",
      "[24]\ttraining's binary_logloss: 0.210621\tvalid_1's binary_logloss: 0.337386\n",
      "[25]\ttraining's binary_logloss: 0.202076\tvalid_1's binary_logloss: 0.331523\n",
      "[26]\ttraining's binary_logloss: 0.194199\tvalid_1's binary_logloss: 0.326349\n",
      "[27]\ttraining's binary_logloss: 0.187107\tvalid_1's binary_logloss: 0.322785\n",
      "[28]\ttraining's binary_logloss: 0.180535\tvalid_1's binary_logloss: 0.317877\n",
      "[29]\ttraining's binary_logloss: 0.173834\tvalid_1's binary_logloss: 0.313928\n",
      "[30]\ttraining's binary_logloss: 0.167198\tvalid_1's binary_logloss: 0.310105\n",
      "[31]\ttraining's binary_logloss: 0.161229\tvalid_1's binary_logloss: 0.307107\n",
      "[32]\ttraining's binary_logloss: 0.155494\tvalid_1's binary_logloss: 0.303837\n",
      "[33]\ttraining's binary_logloss: 0.149125\tvalid_1's binary_logloss: 0.300315\n",
      "[34]\ttraining's binary_logloss: 0.144045\tvalid_1's binary_logloss: 0.297816\n",
      "[35]\ttraining's binary_logloss: 0.139341\tvalid_1's binary_logloss: 0.295387\n",
      "[36]\ttraining's binary_logloss: 0.134625\tvalid_1's binary_logloss: 0.293063\n",
      "[37]\ttraining's binary_logloss: 0.129167\tvalid_1's binary_logloss: 0.289127\n",
      "[38]\ttraining's binary_logloss: 0.12472\tvalid_1's binary_logloss: 0.288697\n",
      "[39]\ttraining's binary_logloss: 0.11974\tvalid_1's binary_logloss: 0.28576\n",
      "[40]\ttraining's binary_logloss: 0.115054\tvalid_1's binary_logloss: 0.282853\n",
      "[41]\ttraining's binary_logloss: 0.110662\tvalid_1's binary_logloss: 0.279441\n",
      "[42]\ttraining's binary_logloss: 0.106358\tvalid_1's binary_logloss: 0.28113\n",
      "[43]\ttraining's binary_logloss: 0.102324\tvalid_1's binary_logloss: 0.279139\n",
      "[44]\ttraining's binary_logloss: 0.0985699\tvalid_1's binary_logloss: 0.276465\n",
      "[45]\ttraining's binary_logloss: 0.094858\tvalid_1's binary_logloss: 0.275946\n",
      "[46]\ttraining's binary_logloss: 0.0912486\tvalid_1's binary_logloss: 0.272819\n",
      "[47]\ttraining's binary_logloss: 0.0883115\tvalid_1's binary_logloss: 0.272306\n",
      "[48]\ttraining's binary_logloss: 0.0849963\tvalid_1's binary_logloss: 0.270452\n",
      "[49]\ttraining's binary_logloss: 0.0821742\tvalid_1's binary_logloss: 0.268671\n",
      "[50]\ttraining's binary_logloss: 0.0789991\tvalid_1's binary_logloss: 0.267587\n",
      "[51]\ttraining's binary_logloss: 0.0761072\tvalid_1's binary_logloss: 0.26626\n",
      "[52]\ttraining's binary_logloss: 0.0732567\tvalid_1's binary_logloss: 0.265542\n",
      "[53]\ttraining's binary_logloss: 0.0706388\tvalid_1's binary_logloss: 0.264547\n",
      "[54]\ttraining's binary_logloss: 0.0683911\tvalid_1's binary_logloss: 0.26502\n",
      "[55]\ttraining's binary_logloss: 0.0659347\tvalid_1's binary_logloss: 0.264388\n",
      "[56]\ttraining's binary_logloss: 0.0636873\tvalid_1's binary_logloss: 0.263128\n",
      "[57]\ttraining's binary_logloss: 0.0613354\tvalid_1's binary_logloss: 0.26231\n",
      "[58]\ttraining's binary_logloss: 0.0591944\tvalid_1's binary_logloss: 0.262011\n",
      "[59]\ttraining's binary_logloss: 0.057033\tvalid_1's binary_logloss: 0.261454\n",
      "[60]\ttraining's binary_logloss: 0.0550801\tvalid_1's binary_logloss: 0.260746\n",
      "[61]\ttraining's binary_logloss: 0.0532381\tvalid_1's binary_logloss: 0.260236\n",
      "[62]\ttraining's binary_logloss: 0.0514074\tvalid_1's binary_logloss: 0.261586\n",
      "[63]\ttraining's binary_logloss: 0.0494837\tvalid_1's binary_logloss: 0.261797\n",
      "[64]\ttraining's binary_logloss: 0.0477826\tvalid_1's binary_logloss: 0.262533\n",
      "[65]\ttraining's binary_logloss: 0.0460364\tvalid_1's binary_logloss: 0.263305\n",
      "[66]\ttraining's binary_logloss: 0.0444552\tvalid_1's binary_logloss: 0.264072\n",
      "[67]\ttraining's binary_logloss: 0.0427638\tvalid_1's binary_logloss: 0.266223\n",
      "[68]\ttraining's binary_logloss: 0.0412449\tvalid_1's binary_logloss: 0.266817\n",
      "[69]\ttraining's binary_logloss: 0.0398589\tvalid_1's binary_logloss: 0.267819\n",
      "[70]\ttraining's binary_logloss: 0.0383095\tvalid_1's binary_logloss: 0.267484\n",
      "[71]\ttraining's binary_logloss: 0.0368803\tvalid_1's binary_logloss: 0.270233\n",
      "[72]\ttraining's binary_logloss: 0.0355637\tvalid_1's binary_logloss: 0.268442\n",
      "[73]\ttraining's binary_logloss: 0.0341747\tvalid_1's binary_logloss: 0.26895\n",
      "[74]\ttraining's binary_logloss: 0.0328302\tvalid_1's binary_logloss: 0.266958\n",
      "[75]\ttraining's binary_logloss: 0.0317853\tvalid_1's binary_logloss: 0.268091\n",
      "[76]\ttraining's binary_logloss: 0.0305626\tvalid_1's binary_logloss: 0.266419\n",
      "[77]\ttraining's binary_logloss: 0.0295001\tvalid_1's binary_logloss: 0.268588\n",
      "[78]\ttraining's binary_logloss: 0.0284699\tvalid_1's binary_logloss: 0.270964\n",
      "[79]\ttraining's binary_logloss: 0.0273953\tvalid_1's binary_logloss: 0.270293\n",
      "[80]\ttraining's binary_logloss: 0.0264668\tvalid_1's binary_logloss: 0.270523\n",
      "[81]\ttraining's binary_logloss: 0.0254636\tvalid_1's binary_logloss: 0.270683\n",
      "[82]\ttraining's binary_logloss: 0.0245911\tvalid_1's binary_logloss: 0.273187\n",
      "[83]\ttraining's binary_logloss: 0.0236486\tvalid_1's binary_logloss: 0.275994\n",
      "[84]\ttraining's binary_logloss: 0.0228047\tvalid_1's binary_logloss: 0.274053\n",
      "[85]\ttraining's binary_logloss: 0.0221693\tvalid_1's binary_logloss: 0.273211\n",
      "[86]\ttraining's binary_logloss: 0.0213043\tvalid_1's binary_logloss: 0.272626\n",
      "[87]\ttraining's binary_logloss: 0.0203934\tvalid_1's binary_logloss: 0.27534\n",
      "[88]\ttraining's binary_logloss: 0.0195552\tvalid_1's binary_logloss: 0.276228\n",
      "[89]\ttraining's binary_logloss: 0.0188623\tvalid_1's binary_logloss: 0.27525\n",
      "[90]\ttraining's binary_logloss: 0.0183664\tvalid_1's binary_logloss: 0.276485\n",
      "[91]\ttraining's binary_logloss: 0.0176788\tvalid_1's binary_logloss: 0.277052\n",
      "[92]\ttraining's binary_logloss: 0.0170059\tvalid_1's binary_logloss: 0.277686\n",
      "[93]\ttraining's binary_logloss: 0.0164317\tvalid_1's binary_logloss: 0.275332\n",
      "[94]\ttraining's binary_logloss: 0.015878\tvalid_1's binary_logloss: 0.276236\n",
      "[95]\ttraining's binary_logloss: 0.0152959\tvalid_1's binary_logloss: 0.274538\n",
      "[96]\ttraining's binary_logloss: 0.0147216\tvalid_1's binary_logloss: 0.275244\n",
      "[97]\ttraining's binary_logloss: 0.0141758\tvalid_1's binary_logloss: 0.275829\n",
      "[98]\ttraining's binary_logloss: 0.0136551\tvalid_1's binary_logloss: 0.276654\n",
      "[99]\ttraining's binary_logloss: 0.0131585\tvalid_1's binary_logloss: 0.277859\n",
      "[100]\ttraining's binary_logloss: 0.0126961\tvalid_1's binary_logloss: 0.279265\n",
      "[101]\ttraining's binary_logloss: 0.0122421\tvalid_1's binary_logloss: 0.276695\n",
      "[102]\ttraining's binary_logloss: 0.0118067\tvalid_1's binary_logloss: 0.278488\n",
      "[103]\ttraining's binary_logloss: 0.0113994\tvalid_1's binary_logloss: 0.278932\n",
      "[104]\ttraining's binary_logloss: 0.0109799\tvalid_1's binary_logloss: 0.280997\n",
      "[105]\ttraining's binary_logloss: 0.0105953\tvalid_1's binary_logloss: 0.281454\n",
      "[106]\ttraining's binary_logloss: 0.0102381\tvalid_1's binary_logloss: 0.282058\n",
      "[107]\ttraining's binary_logloss: 0.00986714\tvalid_1's binary_logloss: 0.279275\n",
      "[108]\ttraining's binary_logloss: 0.00950998\tvalid_1's binary_logloss: 0.281427\n",
      "[109]\ttraining's binary_logloss: 0.00915965\tvalid_1's binary_logloss: 0.280752\n",
      "[110]\ttraining's binary_logloss: 0.00882581\tvalid_1's binary_logloss: 0.282152\n",
      "[111]\ttraining's binary_logloss: 0.00850714\tvalid_1's binary_logloss: 0.280894\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's binary_logloss: 0.0532381\tvalid_1's binary_logloss: 0.260236\n"
     ]
    }
   ],
   "source": [
    "features = X = cancer_df.iloc[:, :-1]\n",
    "labels = y = cancer_df.iloc[:, -1]\n",
    "\n",
    "#전체 데이터 중 80%는 학습용, 20%는 테스트용 데이터 추출\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels,\n",
    "                                                    test_size = 0.2, random_state = 156)\n",
    "\n",
    "#위에서 만든 X_train, y_train을 다시 쪼개서 90%는 학습용, 10%는 검증용 데이터로 분리\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 156)\n",
    "\n",
    "#XGBoost와 동일하게 n_estimators는 400으로 설정\n",
    "lgbm_wrapper = LGBMClassifier(n_estimators = 400, learning_rate = 0.05)\n",
    "\n",
    "#LightGBM도 XGBoost와 동일하게 조기 중단 수행 가능\n",
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_wrapper.fit(X_tr, y_tr, early_stopping_rounds=50, eval_metric = \"logloss\",\n",
    "                eval_set = evals, verbose = True)\n",
    "\n",
    "preds = lgbm_wrapper.predict(X_test)\n",
    "pred_proba = lgbm_wrapper.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d206c2e-e9c0-4541-b7b3-55c99368cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LightGBM 모델을 기반으로 예측 성능 평가\n",
    "get_clf_eval(y_test, preds, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61b036c5-198f-44b2-860c-f3fba04eb552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot_importance()를 이용하여 feature 중요도 시각화\n",
    "from lightgbm import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,12))\n",
    "plot_importance(lgbm_wrapper, ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89796b2a-2453-46f1-b258-02f12bf7476b",
   "metadata": {},
   "source": [
    "### (7) 베이지안 최적화 기반의 HyperOpt를 이용한 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "258927cc-9573-4922-a24b-9733822afb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from hyperopt) (1.21.5)\n",
      "Requirement already satisfied: six in c:\\users\\admin\\anaconda3\\lib\\site-packages (from hyperopt) (1.16.0)\n",
      "Collecting py4j\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\anaconda3\\lib\\site-packages (from hyperopt) (4.64.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from hyperopt) (1.7.3)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from hyperopt) (2.7.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\admin\\anaconda3\\lib\\site-packages (from hyperopt) (2.0.0)\n",
      "Requirement already satisfied: future in c:\\users\\admin\\anaconda3\\lib\\site-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tqdm->hyperopt) (0.4.4)\n",
      "Installing collected packages: py4j, hyperopt\n",
      "Successfully installed hyperopt-0.2.7 py4j-0.10.9.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05c73673-7047-463f-b5c4-eb9aae555733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d67ec65-7c50-4ec2-9b38-72deae8fa276",
   "metadata": {},
   "source": [
    "* HyerOpt 를 활용하는 주요 로직<br>\n",
    "입력 변수명과 입력값의 검색 공간(Search Space) 설정<br>\n",
    "목적 함수(Objective Funtion)의 설정<br>\n",
    "목적 함수의 반환 최소값을 가지는 최적 입력값을 유추하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b066ee33-f505-4fb5-b0bc-f3963716976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-10 ~ 10 까지 1 간격을 가지는 입력 변수 x와 -15 ~ 15 까지 1 간격으로 입력 변수 y 설정\n",
    "#1. 입력값 검색 공간 지정\n",
    "search_space = {'x' : hp.quniform('x', -10, 10, 1), 'y' : hp.quniform('y', -15, 15, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e692c0d-461a-43f0-8588-dbc79425c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "\n",
    "#2. 목적 함수를 생성. 변숫값과 변수 검색 공간을 가지는 딕셔너리를 인자로 받고, 특정 값을 반환\n",
    "def objective_func(search_space):\n",
    "    x = search_space['x']\n",
    "    y = search_space['y']\n",
    "    retval = x**2 - 20*y\n",
    "    \n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4a895c6-78e9-4b82-b40a-c8a199451a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 30.18trial/s, best loss: -224.0]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "#3. 입력 결과값을 저장한 Trials 객체값 생성\n",
    "trial_val = Trials()\n",
    "\n",
    "#목적 함수의 최소값을 반환하는 최적 입력 변수값을 5번의 입력값 시도(max_evals=5)로 찾아냄\n",
    "best01 = fmin(fn = objective_func, space = search_space, algo = tpe.suggest, max_evals=5,\n",
    "    trials = trial_val, rstate = np.random.default_rng(seed=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1d0df52-c8ae-415f-b51e-83aceee18bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': -4.0, 'y': 12.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best01    #x = 0, y = -15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9038e10b-d4ea-41fd-af79-1b3186e828b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 668.47trial/s, best loss: -296.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': 2.0, 'y': 15.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_val = Trials()\n",
    "\n",
    "#max_eval 를 20으로 즐려서 재 테스트\n",
    "best02 = fmin(fn = objective_func, space = search_space, algo = tpe.suggest, max_evals=20,\n",
    "    trials = trial_val, rstate = np.random.default_rng(seed=0))\n",
    "\n",
    "best02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ef5152c-e5cb-4172-a06d-99f8fa9d3a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('x', 2.0), ('y', 15.0)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best02.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0fcaa75-6267-4af3-af34-2087d6bc04cf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [-6.0,\n",
       "  -4.0,\n",
       "  4.0,\n",
       "  -4.0,\n",
       "  9.0,\n",
       "  2.0,\n",
       "  10.0,\n",
       "  -9.0,\n",
       "  -8.0,\n",
       "  -0.0,\n",
       "  -0.0,\n",
       "  1.0,\n",
       "  9.0,\n",
       "  6.0,\n",
       "  9.0,\n",
       "  2.0,\n",
       "  -2.0,\n",
       "  -4.0,\n",
       "  7.0,\n",
       "  -0.0],\n",
       " 'y': [5.0,\n",
       "  10.0,\n",
       "  -2.0,\n",
       "  12.0,\n",
       "  1.0,\n",
       "  15.0,\n",
       "  7.0,\n",
       "  -10.0,\n",
       "  0.0,\n",
       "  -5.0,\n",
       "  -3.0,\n",
       "  2.0,\n",
       "  4.0,\n",
       "  10.0,\n",
       "  3.0,\n",
       "  3.0,\n",
       "  -14.0,\n",
       "  -8.0,\n",
       "  11.0,\n",
       "  -0.0]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_val.vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec11a1c-238c-4ba6-87f0-cd58fffb48ba",
   "metadata": {},
   "source": [
    "#### * HyperOpt를 이용한 XGBoost 하이퍼 파라미터 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24a3e1bf-add6-420f-9afd-129c82a23f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_breast_cancer()\n",
    "X = features = dataset.data\n",
    "y = labels = dataset.target\n",
    "\n",
    "# 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
    "X_train, X_test, y_train, y_test=train_test_split(features, labels,\n",
    "                                         test_size=0.2, random_state=156 )\n",
    "\n",
    "# 위에서 만든 X_train, y_train을 다시 쪼개서 90%는 학습과 10%는 검증용 데이터로 분리  \n",
    "X_tr, X_val, y_tr, y_val= train_test_split(X_train, y_train,\n",
    "                                         test_size=0.1, random_state=156 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b29094b7-5131-4f99-bdbd-b214fbf06902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# max_depth는 5에서 20까지 1간격으로, min_child_weight는 1에서 2까지 1간격으로\n",
    "# colsample_bytree는 0.5에서 1사이, learning_rate는 0.01에서 0.2 사이 정규 분포된 값으로 검색.\n",
    "xgb_search_space = {'max_depth': hp.quniform('max_depth', 5, 20, 1), \n",
    "                    'min_child_weight': hp.quniform('min_child_weight', 1, 2, 1),\n",
    "                    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "                    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "                   } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fba7f151-97cd-432a-90d0-acf1e7bd885f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "# fmin()에서 입력된 search_space 값으로 입력된 모든 값은 실수형임.\n",
    "# XGBClassifier의 정수형 하이퍼 파라미터는 정수형 변환을 해줘야 함.\n",
    "# 정확도는 높을수록 더 좋은 수치임. -1 * 정확도를 곱해서 큰 정확도 값일수록 최소가 되도록 변환\n",
    "def objective_func(search_space):\n",
    "    # 수행 시간 절약을 위해 nestimators는 100으로 축소\n",
    "    xgb_clf = XGBClassifier(n_estimators=100, max_depth=int(search_space['max_depth']),\n",
    "                            min_child_weight=int(search_space['min_child_weight']),\n",
    "                            learning_rate=search_space['learning_rate'],\n",
    "                            colsample_bytree=search_space['colsample_bytree'],\n",
    "                            eval_metric='logloss')\n",
    "    accuracy = cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3)\n",
    "    \n",
    "    # accuracy는 cv=3 개수만큼 roc-auc 결과를 리스트로 가짐. 이를 평균해서 반환하되 -1을 곱함.\n",
    "    return {'loss':-1 * np.mean(accuracy), 'status': STATUS_OK} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bbc51dcf-57e4-48d7-9130-09422f4a57f9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|█▉                                              | 2/50 [00:00<00:09,  4.99trial/s, best loss: -0.9604827466016034]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|███▊                                            | 4/50 [00:00<00:07,  6.47trial/s, best loss: -0.9604827466016034]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|████▊                                           | 5/50 [00:00<00:06,  7.03trial/s, best loss: -0.9626612059951203]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14%|██████▋                                         | 7/50 [00:01<00:06,  6.89trial/s, best loss: -0.9626612059951203]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18%|████████▋                                       | 9/50 [00:01<00:05,  7.42trial/s, best loss: -0.9626612059951203]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█████████▍                                     | 10/50 [00:01<00:05,  7.11trial/s, best loss: -0.9626612059951203]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24%|███████████▎                                   | 12/50 [00:01<00:05,  7.13trial/s, best loss: -0.9626612059951203]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28%|█████████████▏                                 | 14/50 [00:02<00:05,  6.71trial/s, best loss: -0.9626612059951203]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██████████████                                 | 15/50 [00:02<00:05,  6.57trial/s, best loss: -0.9626612059951203]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34%|███████████████▉                               | 17/50 [00:02<00:05,  6.35trial/s, best loss: -0.9626612059951203]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████▊                             | 19/50 [00:02<00:04,  7.14trial/s, best loss: -0.9626612059951203]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████▏                            | 20/50 [00:02<00:04,  7.34trial/s, best loss: -0.964868711513884]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████▏                           | 21/50 [00:03<00:04,  6.62trial/s, best loss: -0.964868711513884]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████                          | 23/50 [00:03<00:03,  7.09trial/s, best loss: -0.964868711513884]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48%|███████████████████████                         | 24/50 [00:03<00:04,  6.32trial/s, best loss: -0.964868711513884]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████▍                      | 26/50 [00:03<00:03,  6.47trial/s, best loss: -0.9670616939700244]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 54%|█████████████████████████▍                     | 27/50 [00:04<00:03,  6.61trial/s, best loss: -0.9670616939700244]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████████▎                   | 29/50 [00:04<00:03,  6.79trial/s, best loss: -0.9670616939700244]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████▏                  | 30/50 [00:04<00:03,  6.44trial/s, best loss: -0.9670616939700244]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64%|██████████████████████████████                 | 32/50 [00:04<00:02,  6.73trial/s, best loss: -0.9670616939700244]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████▉               | 34/50 [00:05<00:02,  6.98trial/s, best loss: -0.9670616939700244]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████▊             | 36/50 [00:05<00:01,  7.31trial/s, best loss: -0.9670616939700244]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 74%|██████████████████████████████████▊            | 37/50 [00:05<00:01,  7.42trial/s, best loss: -0.9670616939700244]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████████████▋          | 39/50 [00:05<00:01,  7.44trial/s, best loss: -0.9670616939700244]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████▌        | 41/50 [00:06<00:01,  7.28trial/s, best loss: -0.9670616939700244]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████▍       | 42/50 [00:06<00:01,  7.17trial/s, best loss: -0.9670616939700244]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████████████████████████████▎     | 44/50 [00:06<00:00,  7.69trial/s, best loss: -0.9670616939700244]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████▏   | 46/50 [00:06<00:00,  7.44trial/s, best loss: -0.9670616939700244]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████████  | 48/50 [00:06<00:00,  7.81trial/s, best loss: -0.9670616939700244]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████████████████ | 49/50 [00:07<00:00,  7.39trial/s, best loss: -0.9670616939700244]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 50/50 [00:07<00:00,  6.91trial/s, best loss: -0.9670616939700244]\n",
      "best: {'colsample_bytree': 0.5424149213362504, 'learning_rate': 0.12601372924444681, 'max_depth': 17.0, 'min_child_weight': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trial_val = Trials()\n",
    "best = fmin(fn=objective_func,\n",
    "            space=xgb_search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50, # 최대 반복 횟수를 지정합니다.\n",
    "            trials=trial_val, rstate=np.random.default_rng(seed=9))\n",
    "print('best:', best) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15f5c00b-f32b-4f1d-9fb7-b9e7c65e45d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(n_estimators=100, max_depth=17,\n",
    "                        min_child_weight=2, learning_rate=0.126,\n",
    "                        colsample_bytree=0.54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2a3039a-6697-4114-ad5f-8e631f57ac73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:52:37] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.956140350877193"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.fit(X_train, y_train)\n",
    "pred = xgb_clf.predict(X_test)\n",
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7e34b4-b40a-4e46-a3cf-198464628f60",
   "metadata": {},
   "source": [
    "### (8) 분류 실습 - 캐글 산탄데르 고객 만족 예측\n",
    "http://naver.me/FXr6wxcL<br>\n",
    "http://naver.me/F6xAnFzd<br>\n",
    "kaggle 사이트 접속, santander 데이터 다운 받기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88593605-c6c8-446f-8a98-67e35fe95e03",
   "metadata": {},
   "source": [
    "#### * 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34e32e33-6d39-4f53-b1e5-3f4cc0bd1369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76015</th>\n",
       "      <td>151829</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60926.490000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76016</th>\n",
       "      <td>151830</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118634.520000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76017</th>\n",
       "      <td>151835</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74028.150000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76018</th>\n",
       "      <td>151836</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84278.160000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76019</th>\n",
       "      <td>151838</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76020 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0           1     2     23                 0.0                      0.0   \n",
       "1           3     2     34                 0.0                      0.0   \n",
       "2           4     2     23                 0.0                      0.0   \n",
       "3           8     2     37                 0.0                    195.0   \n",
       "4          10     2     39                 0.0                      0.0   \n",
       "...       ...   ...    ...                 ...                      ...   \n",
       "76015  151829     2     48                 0.0                      0.0   \n",
       "76016  151830     2     39                 0.0                      0.0   \n",
       "76017  151835     2     23                 0.0                      0.0   \n",
       "76018  151836     2     25                 0.0                      0.0   \n",
       "76019  151838     2     46                 0.0                      0.0   \n",
       "\n",
       "       imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                        195.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "76015                      0.0                      0.0   \n",
       "76016                      0.0                      0.0   \n",
       "76017                      0.0                      0.0   \n",
       "76018                      0.0                      0.0   \n",
       "76019                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "76015                      0.0                      0.0   \n",
       "76016                      0.0                      0.0   \n",
       "76017                      0.0                      0.0   \n",
       "76018                      0.0                      0.0   \n",
       "76019                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_efect_ult3  ...  saldo_medio_var33_hace2  \\\n",
       "0                          0.0  ...                      0.0   \n",
       "1                          0.0  ...                      0.0   \n",
       "2                          0.0  ...                      0.0   \n",
       "3                          0.0  ...                      0.0   \n",
       "4                          0.0  ...                      0.0   \n",
       "...                        ...  ...                      ...   \n",
       "76015                      0.0  ...                      0.0   \n",
       "76016                      0.0  ...                      0.0   \n",
       "76017                      0.0  ...                      0.0   \n",
       "76018                      0.0  ...                      0.0   \n",
       "76019                      0.0  ...                      0.0   \n",
       "\n",
       "       saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                          0.0                     0.0   \n",
       "1                          0.0                     0.0   \n",
       "2                          0.0                     0.0   \n",
       "3                          0.0                     0.0   \n",
       "4                          0.0                     0.0   \n",
       "...                        ...                     ...   \n",
       "76015                      0.0                     0.0   \n",
       "76016                      0.0                     0.0   \n",
       "76017                      0.0                     0.0   \n",
       "76018                      0.0                     0.0   \n",
       "76019                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var33_ult3  saldo_medio_var44_hace2  \\\n",
       "0                         0.0                      0.0   \n",
       "1                         0.0                      0.0   \n",
       "2                         0.0                      0.0   \n",
       "3                         0.0                      0.0   \n",
       "4                         0.0                      0.0   \n",
       "...                       ...                      ...   \n",
       "76015                     0.0                      0.0   \n",
       "76016                     0.0                      0.0   \n",
       "76017                     0.0                      0.0   \n",
       "76018                     0.0                      0.0   \n",
       "76019                     0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var44_hace3  saldo_medio_var44_ult1  \\\n",
       "0                          0.0                     0.0   \n",
       "1                          0.0                     0.0   \n",
       "2                          0.0                     0.0   \n",
       "3                          0.0                     0.0   \n",
       "4                          0.0                     0.0   \n",
       "...                        ...                     ...   \n",
       "76015                      0.0                     0.0   \n",
       "76016                      0.0                     0.0   \n",
       "76017                      0.0                     0.0   \n",
       "76018                      0.0                     0.0   \n",
       "76019                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                         0.0   39205.170000       0  \n",
       "1                         0.0   49278.030000       0  \n",
       "2                         0.0   67333.770000       0  \n",
       "3                         0.0   64007.970000       0  \n",
       "4                         0.0  117310.979016       0  \n",
       "...                       ...            ...     ...  \n",
       "76015                     0.0   60926.490000       0  \n",
       "76016                     0.0  118634.520000       0  \n",
       "76017                     0.0   74028.150000       0  \n",
       "76018                     0.0   84278.160000       0  \n",
       "76019                     0.0  117310.979016       0  \n",
       "\n",
       "[76020 rows x 371 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"1017 santander/train.csv\", encoding = 'latin-1')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c7e678c-6f43-4a16-a549-1939a2fc2ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 371)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eaf0bde-3e09-4ab2-ab6c-a9da37a485e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(111), int64(260)\n",
      "memory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caffdbed-2b9e-4ea0-ba01-b1c26b80e336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'var3', 'var15', 'imp_ent_var16_ult1', 'imp_op_var39_comer_ult1',\n",
       "       'imp_op_var39_comer_ult3', 'imp_op_var40_comer_ult1',\n",
       "       'imp_op_var40_comer_ult3', 'imp_op_var40_efect_ult1',\n",
       "       'imp_op_var40_efect_ult3',\n",
       "       ...\n",
       "       'saldo_medio_var33_hace2', 'saldo_medio_var33_hace3',\n",
       "       'saldo_medio_var33_ult1', 'saldo_medio_var33_ult3',\n",
       "       'saldo_medio_var44_hace2', 'saldo_medio_var44_hace3',\n",
       "       'saldo_medio_var44_ult1', 'saldo_medio_var44_ult3', 'var38', 'TARGET'],\n",
       "      dtype='object', length=371)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22c4d12f-3a37-4ab2-a576-3ced37dd0636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "76015    0\n",
       "76016    0\n",
       "76017    0\n",
       "76018    0\n",
       "76019    0\n",
       "Name: TARGET, Length: 76020, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6bd5968-90e9-4b55-b5ab-12397bc38fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.960431\n",
       "1    0.039569\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#전체 데이터에서 만족과 불만족의 비율(0과 1의 %는?)\n",
    "df['TARGET'].value_counts()\n",
    "df['TARGET'].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beb7cbf3-18f3-40c0-85ab-f71f83e33758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        2\n",
       "2        2\n",
       "3        2\n",
       "4        2\n",
       "        ..\n",
       "76015    2\n",
       "76016    2\n",
       "76017    2\n",
       "76018    2\n",
       "76019    2\n",
       "Name: var3, Length: 76020, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'-999999'를 '2'로 바꾸어 주세요\n",
    "df['var3'].min()\n",
    "df['var3'].replace(-999999, 2)\n",
    "df['var3'] = df['var3'].replace(-999999, 2)\n",
    "df['var3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05c8cc3f-d96a-4638-887b-66e28a63beae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ID 피처는 단순 식별자에 불과하므로 드롭처리\n",
    "df.drop('ID', axis = 1, inplace = True)\n",
    "\n",
    "#피처 세트와 레이블 세트 분리(X의 칼럼개수는 369개)\n",
    "feature = X = df.iloc[:, :-1]\n",
    "label = y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f7d9a65-aba9-4b52-8319-1270ddbafb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 369)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a1de83e-442d-440d-94a8-d455f94402e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.9583\n",
       "1    0.0417\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature, label,\n",
    "                                                    test_size = 0.2, random_state = 0)\n",
    "\n",
    "#TARGET 값(label 값)의 분포도 확인\n",
    "y_train.value_counts() / len(y_train)\n",
    "y_test.value_counts() / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32f7c8e6-a217-4714-93b7-ea5544755c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, y_train 을 다시 학습과 검증 데이터 세트로 분리\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1bc8ec-56c5-4559-a29d-5ad7e56f0366",
   "metadata": {},
   "source": [
    "#### * XGBoost 모델 학습과 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80006191-1170-47f4-b526-d9eed54a3c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2906352d-431a-4363-b3e9-e636808f8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_estimator는 500, random_state는 예제 수행 시 마다 동일 예측 결과를 위해 설정\n",
    "xgb_clf = XGBClassifier(n_estimators = 500, learning_rate = 0.05, random_state = 156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0b2feb3-1b94-47de-8e66-133464ded255",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (501813824.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [24]\u001b[1;36m\u001b[0m\n\u001b[1;33m    pred = xgb_clf.predict(X_test)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#성능 평가 지표를 auc로, 조기 중단 파라미터는 100으로 설정하고 학습 수행\n",
    "xgb_clf.fit(X_tr, y_tr, early_stopping_rounds = 100,\n",
    "            eval_metric = \"auc\", eval_set = [(X_tr, y_tr), (X_val, y_val)])\n",
    "\n",
    "xgb_pred = xgb_clf.predict(X_test)\n",
    "accuracy_score(y_test, xgb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b6e4aba-a514-4ee6-8b6e-a891719ca434",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m xgb_roc_score \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, \u001b[43mxgb_clf\u001b[49m\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      2\u001b[0m xgb_roc_score\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb_clf' is not defined"
     ]
    }
   ],
   "source": [
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\n",
    "xgb_roc_score.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a01e67-f138-46ab-8d14-197ed035c857",
   "metadata": {},
   "source": [
    "#### * HyperOpt를 이용해 베이지안 최적화 기반으로 XGBoost 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75bbe2a7-6557-4011-98bf-10eeb6baca9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (4213458797.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [25]\u001b[1;36m\u001b[0m\n\u001b[1;33m    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)\u001b[0m\n\u001b[1;37m                                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "#하이퍼 파라미터 검색 공간 설정\n",
    "from hyperopt import hp\n",
    "\n",
    "#max_depth는 5~15 1간격으로, min_child_weight는 1~6 1간격으로\n",
    "#colsample_bytree는 0.5~0.95, learning_rate는 0.01~0.2 정규분포된 값으로 검색\n",
    "xgb_search_space = {'max_depth': hp.quniform('max_depth', 5, 15, 1), \n",
    "                    'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n",
    "                    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 0.95),\n",
    "                    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "957fbc12-2988-4c2b-b6b6-b088dc569e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 목적 함수 설정. \n",
    "# 추후 fmin()에서 입력된 search_space값으로 XGBClassifier 교차 검증 학습 후 -1* roc_auc 평균 값을 반환.  \n",
    "def objective_func(search_space):\n",
    "    xgb_clf = XGBClassifier(n_estimators=100, max_depth=int(search_space['max_depth']),\n",
    "                            min_child_weight=int(search_space['min_child_weight']),\n",
    "                            colsample_bytree=search_space['colsample_bytree'],\n",
    "                            learning_rate=search_space['learning_rate'])\n",
    "    \n",
    "    # 3개 k-fold 방식으로 평가된 roc_auc 지표를 담는 list\n",
    "    roc_auc_list= []\n",
    "    \n",
    "    # 3개 k-fold방식 적용 \n",
    "    kf = KFold(n_splits=3)\n",
    "    \n",
    "    # X_train을 다시 학습과 검증용 데이터로 분리 : ( 1/3 , 1/3 ) , ( 1/3 , 1/3 ) , ( 1/3 , 1/3 )\n",
    "    for tr_index, val_index in kf.split(X_train):\n",
    "        # kf.split(X_train)으로 추출된 학습과 검증 index값으로 학습과 검증 데이터 세트 분리 \n",
    "        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n",
    "        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "        \n",
    "        # early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 XGBClassifier 학습 수행.\n",
    "        xgb_clf.fit(X_tr, y_tr, early_stopping_rounds=30, eval_metric='auc',\n",
    "                    eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
    "    \n",
    "        # 1로 예측한 확률값 추출후 roc auc 계산하고 평균 roc auc 계산을 위해 list에 결과값 담음. \n",
    "        score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, 1])\n",
    "        roc_auc_list.append(score)\n",
    "    \n",
    "    # 3개 k-fold로 계산된 roc_auc값의 평균값을 반환하되, \n",
    "    # HyperOpt는 목적함수의 최소값을 위한 입력값을 찾으므로 -1을 곱한 뒤 반환.\n",
    "    #값이 작을 수록 더 좋다\n",
    "    return -1 * np.mean(roc_auc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a4118a6-1429-4b91-82f6-596ca92e920b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_search_space' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m trials \u001b[38;5;241m=\u001b[39m Trials()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# fmin()함수를 호출. max_evals 지정된 횟수만큼 반복 후 목적함수의 최소값을 가지는 최적 입력값 추출.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m best \u001b[38;5;241m=\u001b[39m fmin(fn\u001b[38;5;241m=\u001b[39mobjective_func,\n\u001b[1;32m----> 7\u001b[0m             space\u001b[38;5;241m=\u001b[39m\u001b[43mxgb_search_space\u001b[49m,\n\u001b[0;32m      8\u001b[0m             algo\u001b[38;5;241m=\u001b[39mtpe\u001b[38;5;241m.\u001b[39msuggest,\n\u001b[0;32m      9\u001b[0m             max_evals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, \u001b[38;5;66;03m# 최대 반복 횟수를 지정합니다.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m             trials\u001b[38;5;241m=\u001b[39mtrials, rstate\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mdefault_rng(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m))\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest:\u001b[39m\u001b[38;5;124m'\u001b[39m, best)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb_search_space' is not defined"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "# fmin()함수를 호출. max_evals 지정된 횟수만큼 반복 후 목적함수의 최소값을 가지는 최적 입력값 추출.\n",
    "best = fmin(fn=objective_func,\n",
    "            space=xgb_search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50, # 최대 반복 횟수를 지정합니다.\n",
    "            trials=trials, rstate=np.random.default_rng(seed=30))\n",
    "\n",
    "print('best:', best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfa5e3e-d65b-4fd8-8187-5944b8a721eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_estimator 를 500 증가 후 최적으로 찾은 하이퍼 파라미터를 기반으로 학습과 예측 수행\n",
    "xgb_clf = XGBClassifier(n_estimators = 500, learning_rate = round(best['learning_rate'], 5),\n",
    "                       max_depth = int(best['max_depth']),\n",
    "                       min_child_weight = int(best['min_child_wight']),\n",
    "                       colsample_bytree = round(best['colsample_bytree'], 5))\n",
    "\n",
    "#evaluation metric을 auc로, early stopping은 100으로 설젇하고 학습 수행\n",
    "xgb_clf.fit(X_tr, y_tr, early_stopping_rounds = 100,\n",
    "           eval_metric = \"auc\", eval_set = [(X_tr, y_tr), (X_val, y_val)])\n",
    "\n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predit_proba(X_test)[:, 1])\n",
    "xgb_roc_score.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06e2d15-50cc-4aac-be9b-bb14d174345f",
   "metadata": {},
   "source": [
    "#### * 피처 중요도 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24b5d1e-7524-4a4d-bbe1-f24585d88755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90091b7b-65fc-4dff-85a4-dd5b39014114",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize(10,8))\n",
    "plot_importance(xgb_clf, ax = ax, max_num_features = 20, heifght = 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca67a684-f303-4d8c-b40e-6ca57240e101",
   "metadata": {},
   "source": [
    "#### * LightGBM 모델 학습과 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2301dd8-5c8f-40a4-84e1-8d9af84b4b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators = 500)\n",
    "\n",
    "lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds = 100,\n",
    "             eval_metrics = \"auc\", eval_set = [(X_tr, y_tr), (X_val, y_val)])\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1])\n",
    "lgbm_roc_score.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8256e628-5ade-4533-b817-b4cad3837409",
   "metadata": {},
   "source": [
    "#### * HyperOpt를 이용하여 다양한 하이퍼 파라미터에 대한 튜닝 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f273dea6-cfe0-4505-a6ee-7f8c033c82c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#하이퍼 파라미터 검색 공간 설정\n",
    "lgbm_search_space = {'num_leaves': hp.quniform('num_leaves', 32, 64, 1),\n",
    "                     'max_depth': hp.quniform('max_depth', 100, 160, 1), \n",
    "                     'min_child_samples': hp.quniform('min_child_samples', 60, 100, 1),\n",
    "                     'subsample': hp.uniform('subsample', 0.7, 1),\n",
    "                     'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c2941-1981-4fe7-a3ce-7613ebb7b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#목적 함수 생성 \n",
    "def objective_func(search_space):\n",
    "    lgbm_clf = LGBMClassifier(n_estimators=100, num_leaves=int(search_space['num_leaves']),\n",
    "                              max_depth=int(search_space['max_depth']),\n",
    "                              min_child_samples=int(search_space['min_child_samples']),\n",
    "                              subsample=search_space['subsample'],\n",
    "                              learning_rate=search_space['learning_rate'])\n",
    "    \n",
    "    # 3개 k-fold 방식으로 평가된 roc_auc 지표를 담는 list\n",
    "    roc_auc_list= []\n",
    "    \n",
    "    # 3개 k-fold방식 적용 \n",
    "    kf = KFold(n_splits=3)\n",
    "    \n",
    "    # X_train을 다시 학습과 검증용 데이터로 분리 : ( 1/3 , 1/3 ) , ( 1/3 , 1/3 ) , ( 1/3 , 1/3 )\n",
    "    for tr_index, val_index in kf.split(X_train):\n",
    "        # kf.split(X_train)으로 추출된 학습과 검증 index값으로 학습과 검증 데이터 세트 분리 \n",
    "        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n",
    "        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "        \n",
    "        # early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 XGBClassifier 학습 수행.\n",
    "        lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds=30, eval_metric='auc',\n",
    "                    eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
    "    \n",
    "        # 1로 예측한 확률값 추출후 roc auc 계산하고 평균 roc auc 계산을 위해 list에 결과값 담음. \n",
    "        score = roc_auc_score(y_val, lgbm_clf.predict_proba(X_val)[:, 1])\n",
    "        roc_auc_list.append(score)\n",
    "    \n",
    "    # 3개 k-fold로 계산된 roc_auc값의 평균값을 반환하되, \n",
    "    # HyperOpt는 목적함수의 최소값을 위한 입력값을 찾으므로 -1을 곱한 뒤 반환.\n",
    "    return -1 * np.mean(roc_auc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130394bd-ee8d-45f8-a102-b93c67b16145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fmin()을 호출하여 최적 하이퍼 파라미터 도출\n",
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "#max_evals 지정된 횟수만큼 반복 후 목적함수의 최소값을 가지는 최적 입력값 추출\n",
    "best = fmin(fn = objective_func, space=lgbm_search_space, algo = tpe.suggest,\n",
    "           max_evals = 50,  # 최대 반복 횟수를 지정합니다.\n",
    "           trials = trials, rstate = np.random.default_rng(seed=30))\n",
    "\n",
    "print('best: ', best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35a9df8-9075-425d-a149-b08ddce30548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트 데이터 세트에서 ROC-AUC 평가\n",
    "lgbm_clf = LGBMClassifier(n_estimators = 500, num_leaves = int(best['num_leaves']),\n",
    "                       max_depth = int(best['max_depth']),\n",
    "                       min_child_samples = int(best['min_child_samples']),\n",
    "                       subsample = round(best['subsample'], 5),\n",
    "                       learning_rate = round(best['learning_rate'], 5))\n",
    "\n",
    "#evaluation metric을 auc로, early stopping은 100으로 설젇하고 학습 수행\n",
    "lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds = 100,\n",
    "           eval_metric = \"auc\", eval_set = [(X_tr, y_tr), (X_val, y_val)])\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predit_proba(X_test)[:, 1])\n",
    "lbgm_roc_score.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
